{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização de Consultas no Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive Query Execution (AQE) é um dos melhores recursos do Spark 3.0, que reotimiza e ajusta os planos de consulta com base nas estatísticas de tempo de execução coletadas durante a execução da consulta. \n",
    "\n",
    "Depois de habilitar a AQE, as seguintes melhorias serão realizadas:\n",
    "\n",
    " - Conversão automatica do sort-merge join (lento) para o Broadcast join\n",
    " - Otimização do Skew Join (dados distribuidos de forma desigual entre as partições no cluster)\n",
    "\n",
    "\n",
    "para habilitaro AQS: \n",
    "\n",
    "* spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import databricks.koalas as ks\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Spark Performance Issues\")\\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"false\")\\\n",
    "    .config(\"spark.metrics.conf.*.sink.console.class\", \"org.apache.spark.metrics.sink.ConsoleSink\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulando um desbalanceamento entre as partições (Data Skew)\n",
    "\n",
    "\n",
    "Data Skew é uma condição em que os dados de uma tabela são distribuídos de forma desigual entre as partições no cluster. A distorção de dados pode prejudicar gravemente o desempenho das consultas, especialmente aquelas com junções. As junções entre tabelas grandes exigem dados embaralhados (shuffling) e a distorção pode levar a um  desequilíbrio extremo de trabalho no cluster. É provável que a distorção de dados esteja afetando a performance de uma consulta caso ela pareça estar travada ao termino de poucas tasks (por exemplo, as últimas 3 tasks de 200). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 10)\n",
    "\n",
    "spark.range(1000000)\\\n",
    "    .withColumn(\"join_key\", F.lit(\" \"))\\\n",
    "    .createOrReplaceTempView(\"table_x\")\n",
    "\n",
    "spark.range(1000000)\\\n",
    "    .withColumn(\"join_key\", F.lit(\" \"))\\\n",
    "    .createOrReplaceTempView(\"table_y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código a seguir, será realizado o join entre as duas tabelas, o que irá produzir um output de um trilhão de linhas, e todas elas serão produzidas utilizando um único executor (o executor que obtém a chave \"\"):\n",
    "\n",
    "Esta consulta parece estar em execução. Mas, com apenas uma única task remanescente, quando dispararmos a action. O job permanecerá em execução por um longo período, até falhar. Nesse caso, há apenas uma chave de join problemática. Em outros cenários, podem existir outros fatores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT id, count()\n",
    "    FROM\n",
    "    (\n",
    "        SELECT x.id\n",
    "        FROM table_x x\n",
    "        JOIN table_y y ON x.join_key = y.join_key\n",
    "    )\n",
    "    GROUP BY id\n",
    "\"\"\"\n",
    "\n",
    "df = sql_context.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisa a distribuição dos dados nas das partições\n",
    "for i, part in enumerate(df.rdd.glom().collect()):\n",
    "    print({i: part})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Para resolver o problema de distorção de dados, podemos:\n",
    "\n",
    "* Reparticionar os dados utilizando uma chave distribuída de maneira mais uniforme.\n",
    "* Transmitir (Broadcast) o dataframe menor\n",
    "* Dividir os dados em dados distorcidos e não distorcidos e trabalhar com eles em paralelo redistribuindo os dados distorcidos (replicação diferencial)\n",
    "* Use uma chave aleatória adicional para melhorar a distribuição dos dados (salting).\n",
    "* Usar o broadcast join\n",
    "\n",
    "PS: no plano de execução, observe os operadores Exchange e o scan (como podemos melhorar isso?)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
