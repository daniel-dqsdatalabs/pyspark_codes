{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import configparser as cp\n",
    "import databricks.koalas as ks\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Spark Performance Issues\")\\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"10\")\\\n",
    "    .config(\"spark.metrics.conf.*.sink.console.class\", \"org.apache.spark.metrics.sink.ConsoleSink\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure Data Lake Connection CTEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('DATABRICKS_CONFIG.INI')\n",
    "\n",
    "AZURE_CONTAINER = config['AZURE']['AZURE_FILE_SYSTEM']\n",
    "AZURE_BASE_FOLDER = config['AZURE']['AZURE_BASE_FOLDER']\n",
    "STORAGE_ACCOUNT_NAME = config['STORAGE_ACCOUNT']['STORAGE_ACCOUNT_NAME']\n",
    "STORAGE_ACCOUNT_KEY = config['STORAGE_ACCOUNT']['STORAGE_ACCOUNT_KEY']\n",
    "DATABRICKS_SECRET = config['DATABRICKS_ACCOUNT']['DATABRICKS_SECRET']\n",
    "DATABRICKS_CLIENT_ID = config['DATABRICKS_ACCOUNT']['DATABRICKS_CLIENT_ID']\n",
    "DATABRICKS_DIRECTORY_ID = config['DATABRICKS_ACCOUNT']['DATABRICKS_DIRECTORY_ID']\n",
    "DATABRICKS_ENDPOINT = \"https://login.microsoftonline.com/{}/oauth2/token\".format(DATABRICKS_DIRECTORY_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "           \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "           \"fs.azure.account.oauth2.client.id\": DATABRICKS_CLIENT_ID,\n",
    "           \"fs.azure.account.oauth2.client.secret\": DATABRICKS_SECRET,\n",
    "           \"fs.azure.account.oauth2.client.endpoint\": DATABRICKS_ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mount(\n",
    "  source = \"abfss://{}@{}.dfs.core.windows.net/\".format(AZURE_CONTAINER, STORAGE_ACCOUNT_NAME),\n",
    "  mount_point = \"/mnt/datalake\",\n",
    "  extra_configs = configs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continua..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
